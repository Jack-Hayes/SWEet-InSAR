{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 000_hyp3?\n",
    "\n",
    "I'm new to hyp3 and InSAR processing in general, so this is exploratory and saved for my own sake. This is with Sentinel-1 burst regular SLCs rather than the OPERA CSLCs found in notebooks/00_SAR_intro.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import asf_search\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the SNOTEL sites for a search bbox\n",
    "gf_snotel = gpd.read_file(\n",
    "    \"https://github.com/egagli/snotel_ccss_stations/raw/main/all_stations.geojson\"\n",
    "    ).set_index(\"code\")\n",
    "gf_snotel = gf_snotel[gf_snotel.network == \"SNOTEL\"].reset_index()\n",
    "sntl_codes = ['589_CO_SNTL', '1185_CO_SNTL', '465_CO_SNTL', \n",
    "              '586_CO_SNTL', '629_CO_SNTL', '713_CO_SNTL', '538_CO_SNTL']\n",
    "gf_snotel_co_4326 = gf_snotel[gf_snotel.code.isin(sntl_codes)]\n",
    "gf_snotel_co_utm = gf_snotel_co_4326.to_crs(\"EPSG:32612\")\n",
    "\n",
    "bounds = gf_snotel_co_4326.total_bounds\n",
    "gf_search = gpd.GeoDataFrame(\n",
    "    geometry=[box(bounds[0], bounds[1], bounds[2], bounds[3])],\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "wkt_search = gf_search.geometry.to_wkt().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = {\n",
    "        #'dataset':asf_search.DATASET.OPERA_S1, \n",
    "        'dataset':'SLC-BURST',\n",
    "        #'processingLevel':asf_search.PRODUCT_TYPE.SLC,\n",
    "        'intersectsWith':wkt_search,\n",
    "        #'operaBurstID':['T049_103322_IW2', 'T129_275785_IW1'],\n",
    "        'fullBurstID':['049_103322_IW2', '129_275785_IW1'],\n",
    "        'start':'2018-01-01T00:00:00Z',\n",
    "        'end':'2018-01-31T00:00:00Z',\n",
    "        'flightDirection':asf_search.FLIGHT_DIRECTION.DESCENDING,\n",
    "        'polarization':asf_search.POLARIZATION.VV,\n",
    "        #'polarization':'VV+VH',\n",
    "        'maxResults':100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "burst_hits = asf_search.search(**parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyp3_sdk import HyP3\n",
    "import hyp3_sdk as sdk\n",
    "hyp3 = HyP3(username=os.environ.get('EARTHDATA_USERNAME'), password=os.environ.get('EARTHDATA_PASSWORD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nbviewer.org/github/ASFHyP3/hyp3-sdk/blob/main/docs/sdk_example.ipynb\n",
    "def get_nearest_neighbors(granule: str, max_neighbors: int | None = None) -> asf_search.ASFSearchResults:\n",
    "    granule = asf_search.granule_search(granule)[-1]\n",
    "    stack = reversed([item for item in granule.stack() if item.properties['temporalBaseline'] < 0])\n",
    "    return asf_search.ASFSearchResults(stack)[:max_neighbors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "granules = [burst_hits[-1].properties.get('url').split(\"/\")[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2efbaa8fa84a08ad106ea2604844f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 HyP3 Jobs: 0 succeeded, 0 failed, 0 running, 1 pending.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm  # For a nice progress bar: https://github.com/tqdm/tqdm#ipython-jupyter-integration\n",
    "insar_jobs = sdk.Batch()\n",
    "for reference in tqdm(granules):\n",
    "    neighbors = get_nearest_neighbors(reference, max_neighbors=1)\n",
    "    for secondary in neighbors:\n",
    "        insar_jobs += hyp3.submit_insar_job(reference, \n",
    "                                            secondary.properties['sceneName'],\n",
    "                                            name='insar-test',\n",
    "                                            )\n",
    "print(insar_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch([Job.from_dict({'credit_cost': 10, 'job_id': 'd17aa057-5efa-4b31-affe-405919483252', 'status_code': 'PENDING', 'job_type': 'INSAR_GAMMA', 'priority': 9950, 'request_time': '2025-02-18T00:19:07+00:00', 'job_parameters': {'include_look_vectors': False, 'include_los_displacement': False, 'include_displacement_maps': False, 'include_inc_map': False, 'include_dem': False, 'include_wrapped_phase': False, 'apply_water_mask': False, 'looks': '20x4', 'phase_filter_parameter': 0.6, 'granules': ['S1A_IW_SLC__1SDV_20180102T131824_20180102T131851_019976_02206D_BCB8', 'S1A_IW_SLC__1SDV_20250125T131849_20250125T131916_057601_0718CF_2F2C']}, 'name': 'insar-test', 'user_id': 'jeghayes'})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insar_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many credits do i have with earthdata??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Below is a struggle to use [hyp3-isce2](https://github.com/ASFHyP3/hyp3-isce2) with Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "granule_1 = burst_hits[-1].properties.get('fileID')\n",
    "granule_2 = burst_hits[-2].properties.get('fileID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable SSL verification, otherwise timeout on 'requests' to download sar-mpc.eu\n",
    "cmd = f\"\"\"docker run -it --rm \\\\\n",
    "  -v /home/jehayes/sh_final/insar/output/desc:/tmp/output \\\\\n",
    "  -e EARTHDATA_USERNAME={os.environ.get('EARTHDATA_USERNAME')} \\\\\n",
    "  -e EARTHDATA_PASSWORD={os.environ.get('EARTHDATA_PASSWORD')} \\\\\n",
    "  -e PYTHONHTTPSVERIFY=0 \\\\\n",
    "  ghcr.io/asfhyp3/hyp3-isce2:latest \\\\\n",
    "  ++process insar_tops_burst \\\\\n",
    "  --reference {granule_1} \\\\\n",
    "  --secondary {granule_2} \\\\\n",
    "  --looks 20x4 \\\\\n",
    "  --apply-water-mask True\n",
    "\"\"\"\n",
    "#print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the command runs without error in ~5 mins, but the outputs are not saved...\n",
    "# TODO: :'(\n",
    "!{cmd}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coincident",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
